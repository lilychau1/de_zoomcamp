{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_version = pyspark.__version__\n",
    "kafka_jar_package = f'org.apache.spark:spark-sql-kafka-0-10_2.12:{pyspark_version}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('GreenTripsConsumer') \\\n",
    "    .config('spark.jars.packages', kafka_jar_package) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_stream = spark \\\n",
    "    .readStream \\\n",
    "    .format('kafka') \\\n",
    "    .option('kafka.bootstrap.servers', 'localhost:9092') \\\n",
    "    .option('subscribe', 'green-trips') \\\n",
    "    .option('startingOffsets', 'earliest') \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek(mini_batch, batch_id):\n",
    "    first_row = mini_batch.take(1)\n",
    "\n",
    "    if first_row:\n",
    "        print(first_row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType() \\\n",
    "    .add('lpep_pickup_datetime', types.StringType()) \\\n",
    "    .add('lpep_dropoff_datetime', types.StringType()) \\\n",
    "    .add('PULocationID', types.IntegerType()) \\\n",
    "    .add('DOLocationID', types.IntegerType()) \\\n",
    "    .add('passenger_count', types.DoubleType()) \\\n",
    "    .add('trip_distance', types.DoubleType()) \\\n",
    "    .add('tip_amount', types.DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_stream = green_stream \\\n",
    "    .select(F.from_json(F.col('value').cast('STRING'), schema).alias('data')) \\\n",
    "    .select('data.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = green_stream.writeStream.foreachBatch(peek).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_destinations = green_stream \\\n",
    "    .withColumn('timestamp', F.current_timestamp()) \\\n",
    "    .groupBy(F.window(F.col('timestamp'), '5 minutes'), 'DOLocationID') \\\n",
    "    .count() \\\n",
    "    .orderBy('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = popular_destinations \\\n",
    "    .writeStream \\\n",
    "    .outputMode('complete') \\\n",
    "    .format('console') \\\n",
    "    .option('truncate', 'false') \\\n",
    "    .start()\n",
    "query2.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homework-kafka-_4Rym6bQ-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
